home <- read.csv('~/Dropbox/Harvard/Senior Spring/CS227/Final Project/src/home_dist.csv', header=TRUE)
home
home[2]
home[]
home[]
home[3]
max(home[3])
min(home[3])
home[3][0]
home[home[home[1]==i][3][1,]3]
home[home[1]==1][3][1,]
home[home[1]==1][3]
home[home[1]==1][3] = 5
home[home[1]==1][3] <- 5
home[home[1]==1][3][1,]
home[3][home[1]==1] <- 5
home[home[1]==1][3]
counts = home[3]
length(counts)
counts
counts[1]
length(counts[1])
counts[0]
counts[1]
counts[2]
counts[1][0]
counts(1,5)
head(counts, 5)
vector = c()
vector[1] <- 1
vector
for (value in head(counts, 5)) {
print(value) }
for (value in head(counts, 5)) {
vector[1] <- value }
class(5)
for (value in head(counts, 5)) {
print(class(value)) }
for (value in head(counts, 5)) {
vector[1] = value }
vector[1]
head(counts, 5)[1]
head(counts, 5)/1000
counts/1000
max(counts)
counts = counts / max(counts)
counts
df
all_user_commutes <- data.frame(home = numeric(0), commute = numeric(0))
all_user_commutes[1,] <- c(1, 1)
all_user_commutes[2,] <- c(2, 1)
all_user_commutes[3,] <- c(2, 2)
table(all_user_commutes)
1:100
median = 3
lambda <- median / log(2)
  exponential_distribution <- function(x) {
    return(lambda * exp(-1 * lambda * x))
  }
R <- 1:100
probabilities <- exponential_distribution(R)
probabilities
able(all_user_commutes)
table(all_user_commutes)
table(all_user_commutes)[0]
table(all_user_commutes)['home']
a = table(all_user_commutes)
sum(a)
a / sum(a)
table(all_user_commutes)
length(table(all_user_commutes))
names(table(all_user_commutes))
mget
mget(table(all_user_commutes))
unique(unlist(all_user_commutes, use.names = FALSE))
c(1,2,3)
med(c(1,2,3))
median(c(1,2,3))
median(c(1,2,3,4,5))
vector()
data.frame(id=numeric(), bins=vector())
a = data.frame(id=numeric(), bins=vector())
c(1, c(1,2))
a[1,] <- c(1, c(1,2))
a,b <- 1, 2
